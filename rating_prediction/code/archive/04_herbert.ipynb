{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T10:16:06.439872Z","iopub.status.busy":"2023-02-27T10:16:06.439066Z","iopub.status.idle":"2023-02-27T10:16:19.580524Z","shell.execute_reply":"2023-02-27T10:16:19.578824Z","shell.execute_reply.started":"2023-02-27T10:16:06.439815Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","import numpy as np\n","from transformers import HerbertTokenizer, RobertaModel\n","from torch import nn\n","from transformers import BertModel\n","from sklearn import metrics\n","from torch.optim import Adam\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-02-27T10:16:19.586060Z","iopub.status.busy":"2023-02-27T10:16:19.584624Z","iopub.status.idle":"2023-02-27T10:16:21.674386Z","shell.execute_reply":"2023-02-27T10:16:21.673136Z","shell.execute_reply.started":"2023-02-27T10:16:19.586000Z"},"trusted":true},"outputs":[],"source":["reviews = pd.read_parquet('../data/reviews_sample_proc.parquet')\n","train = reviews.query('partition == \"train\"')\n","test = reviews.query('partition == \"test\"')\n","\n","original_train = train[['original', 'rating']].rename(columns={'original': 'text'}).assign(**{'rating': lambda x: x['rating']-1})[:100]\n","original_test = test[['original', 'rating']].rename(columns={'original': 'text'}).assign(**{'rating': lambda x: x['rating']-1})"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T10:16:21.676886Z","iopub.status.busy":"2023-02-27T10:16:21.676398Z","iopub.status.idle":"2023-02-27T10:16:31.044793Z","shell.execute_reply":"2023-02-27T10:16:31.043553Z","shell.execute_reply.started":"2023-02-27T10:16:21.676837Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLMTokenizer'. \n","The class this function is called from is 'HerbertTokenizer'.\n"]}],"source":["tokenizer = HerbertTokenizer.from_pretrained('allegro/herbert-klej-cased-tokenizer-v1')\n","\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        self.labels = df['rating'].to_list()\n","        self.texts = [\n","            tokenizer(text, padding='max_length', max_length = 512,\n","                truncation=True, return_tensors='pt') for text in df['text']\n","        ]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_batch_labels(self, idx):\n","        return np.array(self.labels[idx])\n","\n","    def get_batch_texts(self, idx):\n","        return self.texts[idx]\n","\n","    def __getitem__(self, idx):\n","\n","        batch_texts = self.get_batch_texts(idx)\n","        batch_y = self.get_batch_labels(idx)\n","\n","        return batch_texts, batch_y\n","    \n","class RobertaClassifier(nn.Module):\n","\n","    def __init__(self):\n","\n","        super().__init__()\n","\n","        self.bert = RobertaModel.from_pretrained('allegro/herbert-klej-cased-v1')\n","        self.linear = nn.Linear(768, 5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, input_id, mask):\n","\n","        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n","        linear_output = self.linear(pooled_output)\n","        final_layer = self.relu(linear_output)\n","\n","        return final_layer"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T10:16:31.048538Z","iopub.status.busy":"2023-02-27T10:16:31.048023Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91e8df21c1944f68ae739388419c05b8","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"396306c299ac41f58449d0604ed9aff6","version_major":2,"version_minor":0},"text/plain":["Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/500M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["100%|██████████| 7/7 [00:39<00:00,  5.66s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epochs: 1 | Train Loss:  0.114             | Train Accuracy:  0.150\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 7/7 [00:38<00:00,  5.52s/it]"]},{"name":"stdout","output_type":"stream","text":["Epochs: 2 | Train Loss:  0.113             | Train Accuracy:  0.210\n","CPU times: user 3min 5s, sys: 49.4 s, total: 3min 55s\n","Wall time: 1min 35s\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["%%time\n","\n","torch.manual_seed(1234)\n","\n","def train(model, train_data, learning_rate, epochs):\n","\n","    train = Dataset(train_data)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr=learning_rate)\n","\n","    if use_cuda:\n","            model = model.cuda()\n","            criterion = criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","\n","        total_acc_train = 0\n","        total_loss_train = 0\n","\n","        for train_input, train_label in tqdm(train_dataloader):\n","\n","            train_label = train_label.to(device)\n","            mask = train_input['attention_mask'].to(device)\n","            input_id = train_input['input_ids'].squeeze(1).to(device)\n","\n","            output = model(input_id, mask)\n","\n","            batch_loss = criterion(output, train_label.long())\n","            total_loss_train += batch_loss.item()\n","\n","            acc = (output.argmax(dim=1) == train_label).sum().item()\n","            total_acc_train += acc\n","\n","            model.zero_grad()\n","            batch_loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","\n","        print(\n","            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n","            | Train Accuracy: {total_acc_train / len(train_data): .3f}'\n","        )\n","                  \n","EPOCHS = 2\n","model = RobertaClassifier()\n","\n","modules = [model.bert.embeddings, *model.bert.encoder.layer[:8]]\n","for module in modules:\n","    for param in module.parameters():\n","        param.requires_grad = False\n","        \n","LR = 5e-5\n","              \n","train(model, translated_train, LR, EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def evaluate(model, test_data):\n","\n","    test = Dataset(test_data)\n","\n","    test_dataloader = torch.utils.data.DataLoader(test, batch_size=16)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    y_pred = torch.empty(0) .to(device)\n","\n","    with torch.no_grad():\n","        for test_input, test_label in test_dataloader:\n","            \n","            test_label = test_label.to(device)\n","            mask = test_input['attention_mask'].to(device)\n","            input_id = test_input['input_ids'].squeeze(1).to(device)\n","\n","            output = model(input_id, mask)\n","\n","            y_pred = torch.cat([y_pred, output.argmax(dim=1)])\n","    \n","    return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","\n","results = evaluate(model, translated_test)\n","\n","print(metrics.classification_report(translated_test['rating'].to_numpy(), results.cpu().numpy()))"]}],"metadata":{"kernelspec":{"display_name":"tmsmm","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"056f66996a9c4d81c65e6002a1ca08da18a62e1c6e37a0ec081f5552e597d624"}}},"nbformat":4,"nbformat_minor":4}
