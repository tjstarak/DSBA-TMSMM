{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\n\nfrom mlxtend.preprocessing import DenseTransformer\n\nimport optuna\nfrom optuna.samplers import TPESampler","metadata":{"execution":{"iopub.status.busy":"2023-02-17T12:11:12.178417Z","iopub.execute_input":"2023-02-17T12:11:12.179503Z","iopub.status.idle":"2023-02-17T12:11:13.673830Z","shell.execute_reply.started":"2023-02-17T12:11:12.179388Z","shell.execute_reply":"2023-02-17T12:11:13.672784Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"reviews = pd.read_parquet('/kaggle/input/restaurant-reviews/reviews_sample_proc.parquet')\ntrain = reviews.query('partition == \"train\"')\ntest = reviews.query('partition == \"test\"')\n\nscope = 'original'\nX_train = train[scope].to_numpy()\ny_train = train['rating'].to_numpy() - 1\n\nX_test = test[scope].to_numpy()\ny_test = test['rating'].to_numpy() - 1","metadata":{"execution":{"iopub.status.busy":"2023-02-17T12:11:57.903427Z","iopub.execute_input":"2023-02-17T12:11:57.903797Z","iopub.status.idle":"2023-02-17T12:11:58.882963Z","shell.execute_reply.started":"2023-02-17T12:11:57.903764Z","shell.execute_reply":"2023-02-17T12:11:58.881833Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(min_df=200)\nX_train_vec = vectorizer.fit_transform(X_train[:10000])\nX_train_vec.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-17T12:34:54.581581Z","iopub.execute_input":"2023-02-17T12:34:54.581935Z","iopub.status.idle":"2023-02-17T12:34:55.123900Z","shell.execute_reply.started":"2023-02-17T12:34:54.581905Z","shell.execute_reply":"2023-02-17T12:34:55.122943Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(10000, 369)"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Example of Bayesian optimization for max tree depth (the rest","metadata":{}},{"cell_type":"code","source":"%%time\n\ndef objective(trial):\n    params = {\n        'eta': 0.3,\n        'max_depth': 8,\n        'alpha': trial.suggest_float('alpha', low=0.0, high=0.3, step=0.01),\n        'objective': 'multi:softmax',\n        'num_class': 5,\n        'eval_metric': 'mlogloss',\n        'early_stopping_rounds': 5,\n        'n_estimators': 200,\n        'tree_method': 'gpu_hist',\n    }\n\n    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n\n    y_preds = []\n    y_true = []\n    scores = []\n    n_rounds = []\n    for (train_ix, test_ix) in cv.split(X_train, y_train):\n        vectorizer = TfidfVectorizer(min_df=200)\n        X_train_vec = vectorizer.fit_transform(X_train[train_ix])\n        X_val_vec = vectorizer.transform(X_train[test_ix])\n        clf = xgb.XGBClassifier(**params)\n        clf.fit(X_train_vec, y_train[train_ix], eval_set=[(X_val_vec, y_train[test_ix])], verbose=False)\n        scores.append(clf.best_score)\n        n_rounds.append(clf.best_iteration)\n        y_preds.extend(clf.predict(X_val_vec))\n        y_true.extend(y_train[test_ix])\n\n    score = metrics.f1_score(y_true, y_preds, average='macro')\n    print(np.mean(n_rounds))\n    \n    return score\n\nstudy = optuna.create_study(sampler=TPESampler(), direction='maximize')\nstudy.optimize(objective, n_trials=20)\n\ncols = ['Iteration number', 'Score'] + list(study.best_params.keys())\nresults = [study.best_trial.number, study.best_trial.value] + list(study.best_params.values())\nresults_df = pd.DataFrame([results], columns = cols)\nresults_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Finding the optimal number of boosting rounds","metadata":{}},{"cell_type":"code","source":"%%time\n\nparams = {\n    'eta': 0.1,\n    'max_depth': 8,\n    'alpha': 0.2,\n    'objective': 'multi:softmax',\n    'num_class': 5,\n    'eval_metric': 'mlogloss',\n    'early_stopping_rounds': 10,\n    'n_estimators': 1000,\n    'tree_method': 'gpu_hist',\n}\n\ncv = StratifiedKFold(n_splits=3, shuffle=True, random_state=123)\n\ny_preds = []\ny_true = []\nscores = []\nn_rounds = []\nfor (train_ix, test_ix) in cv.split(X_train, y_train):\n    vectorizer = TfidfVectorizer(min_df=200)\n    X_train_vec = vectorizer.fit_transform(X_train[train_ix])\n    X_val_vec = vectorizer.transform(X_train[test_ix])\n    clf = xgb.XGBClassifier(**params)\n    clf.fit(X_train_vec, y_train[train_ix], eval_set=[(X_val_vec, y_train[test_ix])], verbose=False)\n    scores.append(clf.best_score)\n    n_rounds.append(clf.best_iteration)\n    y_preds.extend(clf.predict(X_val_vec))\n    y_true.extend(y_train[test_ix])\n\nscore = metrics.f1_score(y_true, y_preds, average='macro')\nprint(np.mean(n_rounds))\nprint(score)","metadata":{"execution":{"iopub.status.busy":"2023-02-17T12:24:37.430220Z","iopub.execute_input":"2023-02-17T12:24:37.430890Z","iopub.status.idle":"2023-02-17T12:29:33.140399Z","shell.execute_reply.started":"2023-02-17T12:24:37.430853Z","shell.execute_reply":"2023-02-17T12:29:33.139096Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"605.3333333333334\n0.5618651987997275\nCPU times: user 5min 6s, sys: 424 ms, total: 5min 6s\nWall time: 4min 55s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Polish text, raw (punctuation removed)","metadata":{}},{"cell_type":"code","source":"%%time\n\nscope = 'original'\nX_train = train[scope].to_numpy()\ny_train = train['rating'].to_numpy() - 1\n\nX_test = test[scope].to_numpy()\ny_test = test['rating'].to_numpy() - 1\n\nparams = {\n    'eta': 0.1,\n    'max_depth': 8,\n    'alpha': 0.2,\n    'objective': 'multi:softmax',\n    'num_class': 5,\n    'eval_metric': 'mlogloss',\n    'n_estimators': 605,\n    'tree_method': 'gpu_hist',\n}\n\nvectorizer = TfidfVectorizer(min_df=200)\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\n\nclf = xgb.XGBClassifier(**params)\nclf.fit(X_train_vec, y_train, verbose=False)\n\ny_pred = clf.predict(X_test_vec)\n\nprint(metrics.classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-17T12:42:02.940426Z","iopub.execute_input":"2023-02-17T12:42:02.940789Z","iopub.status.idle":"2023-02-17T12:44:21.379339Z","shell.execute_reply.started":"2023-02-17T12:42:02.940751Z","shell.execute_reply":"2023-02-17T12:44:21.377227Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.64      0.71      0.68      2500\n           1       0.46      0.42      0.44      2500\n           2       0.45      0.45      0.45      2500\n           3       0.55      0.52      0.53      2500\n           4       0.76      0.77      0.77      2500\n\n    accuracy                           0.58     12500\n   macro avg       0.57      0.58      0.57     12500\nweighted avg       0.57      0.58      0.57     12500\n\nCPU times: user 2min 20s, sys: 147 ms, total: 2min 21s\nWall time: 2min 18s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Polish text, lemmatized","metadata":{}},{"cell_type":"code","source":"%%time\n\nscope = 'original_proc'\nX_train = train[scope].to_numpy()\ny_train = train['rating'].to_numpy() - 1\n\nX_test = test[scope].to_numpy()\ny_test = test['rating'].to_numpy() - 1\n\nparams = {\n    'eta': 0.1,\n    'max_depth': 8,\n    'alpha': 0.2,\n    'objective': 'multi:softmax',\n    'num_class': 5,\n    'eval_metric': 'mlogloss',\n    'n_estimators': 605,\n    'tree_method': 'gpu_hist',\n}\n\nvectorizer = TfidfVectorizer(min_df=200)\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\n\nclf = xgb.XGBClassifier(**params)\nclf.fit(X_train_vec, y_train, verbose=False)\n\ny_pred = clf.predict(X_test_vec)\n\nprint(metrics.classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-17T12:56:45.009272Z","iopub.execute_input":"2023-02-17T12:56:45.009616Z","iopub.status.idle":"2023-02-17T12:58:52.753244Z","shell.execute_reply.started":"2023-02-17T12:56:45.009587Z","shell.execute_reply":"2023-02-17T12:58:52.751964Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.65      0.70      0.68      2500\n           1       0.45      0.43      0.44      2500\n           2       0.45      0.46      0.46      2500\n           3       0.55      0.52      0.53      2500\n           4       0.76      0.78      0.77      2500\n\n    accuracy                           0.58     12500\n   macro avg       0.57      0.58      0.57     12500\nweighted avg       0.57      0.58      0.57     12500\n\nCPU times: user 2min 10s, sys: 157 ms, total: 2min 10s\nWall time: 2min 7s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Polish text, lemmatized with stopwords removed","metadata":{}},{"cell_type":"code","source":"%%time\n\nscope = 'original_proc_no_stop'\nX_train = train[scope].to_numpy()\ny_train = train['rating'].to_numpy() - 1\n\nX_test = test[scope].to_numpy()\ny_test = test['rating'].to_numpy() - 1\n\nparams = {\n    'eta': 0.1,\n    'max_depth': 8,\n    'alpha': 0.2,\n    'objective': 'multi:softmax',\n    'num_class': 5,\n    'eval_metric': 'mlogloss',\n    'n_estimators': 605,\n    'tree_method': 'gpu_hist',\n}\n\nvectorizer = TfidfVectorizer(min_df=200)\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\n\nclf = xgb.XGBClassifier(**params)\nclf.fit(X_train_vec, y_train, verbose=False)\n\ny_pred = clf.predict(X_test_vec)\n\nprint(metrics.classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-17T12:59:52.425795Z","iopub.execute_input":"2023-02-17T12:59:52.426173Z","iopub.status.idle":"2023-02-17T13:01:36.773838Z","shell.execute_reply.started":"2023-02-17T12:59:52.426140Z","shell.execute_reply":"2023-02-17T13:01:36.772793Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.64      0.70      0.67      2500\n           1       0.43      0.40      0.42      2500\n           2       0.43      0.42      0.43      2500\n           3       0.54      0.52      0.53      2500\n           4       0.74      0.77      0.75      2500\n\n    accuracy                           0.56     12500\n   macro avg       0.56      0.56      0.56     12500\nweighted avg       0.56      0.56      0.56     12500\n\nCPU times: user 1min 47s, sys: 150 ms, total: 1min 47s\nWall time: 1min 44s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### English translation, raw (with punctuation removed)","metadata":{}},{"cell_type":"code","source":"%%time\n\nscope = 'translated'\nX_train = train[scope].to_numpy()\ny_train = train['rating'].to_numpy() - 1\n\nX_test = test[scope].to_numpy()\ny_test = test['rating'].to_numpy() - 1\n\nparams = {\n    'eta': 0.1,\n    'max_depth': 8,\n    'alpha': 0.2,\n    'objective': 'multi:softmax',\n    'num_class': 5,\n    'eval_metric': 'mlogloss',\n    'n_estimators': 605,\n    'tree_method': 'gpu_hist',\n}\n\nvectorizer = TfidfVectorizer(min_df=200)\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\n\nclf = xgb.XGBClassifier(**params)\nclf.fit(X_train_vec, y_train, verbose=False)\n\ny_pred = clf.predict(X_test_vec)\n\nprint(metrics.classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-17T13:03:54.200758Z","iopub.execute_input":"2023-02-17T13:03:54.201592Z","iopub.status.idle":"2023-02-17T13:06:12.943037Z","shell.execute_reply.started":"2023-02-17T13:03:54.201535Z","shell.execute_reply":"2023-02-17T13:06:12.941770Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.67      0.72      0.69      2500\n           1       0.46      0.43      0.44      2500\n           2       0.44      0.44      0.44      2500\n           3       0.55      0.54      0.54      2500\n           4       0.77      0.78      0.78      2500\n\n    accuracy                           0.58     12500\n   macro avg       0.58      0.58      0.58     12500\nweighted avg       0.58      0.58      0.58     12500\n\nCPU times: user 2min 21s, sys: 195 ms, total: 2min 21s\nWall time: 2min 18s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### English text, lemmatized","metadata":{}},{"cell_type":"code","source":"%%time\n\nscope = 'translated_proc'\nX_train = train[scope].to_numpy()\ny_train = train['rating'].to_numpy() - 1\n\nX_test = test[scope].to_numpy()\ny_test = test['rating'].to_numpy() - 1\n\nparams = {\n    'eta': 0.1,\n    'max_depth': 8,\n    'alpha': 0.2,\n    'objective': 'multi:softmax',\n    'num_class': 5,\n    'eval_metric': 'mlogloss',\n    'n_estimators': 605,\n    'tree_method': 'gpu_hist',\n}\n\nvectorizer = TfidfVectorizer(min_df=200)\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\n\nclf = xgb.XGBClassifier(**params)\nclf.fit(X_train_vec, y_train, verbose=False)\n\ny_pred = clf.predict(X_test_vec)\n\nprint(metrics.classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-17T13:09:19.411194Z","iopub.execute_input":"2023-02-17T13:09:19.411596Z","iopub.status.idle":"2023-02-17T13:11:24.086980Z","shell.execute_reply.started":"2023-02-17T13:09:19.411556Z","shell.execute_reply":"2023-02-17T13:11:24.085966Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.66      0.71      0.69      2500\n           1       0.44      0.42      0.43      2500\n           2       0.44      0.44      0.44      2500\n           3       0.55      0.54      0.55      2500\n           4       0.77      0.78      0.77      2500\n\n    accuracy                           0.58     12500\n   macro avg       0.57      0.58      0.58     12500\nweighted avg       0.57      0.58      0.58     12500\n\nCPU times: user 2min 7s, sys: 169 ms, total: 2min 7s\nWall time: 2min 4s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### English text, lemmatized with stopwords removed","metadata":{}},{"cell_type":"code","source":"%%time\n\nscope = 'translated_proc_no_stop'\nX_train = train[scope].to_numpy()\ny_train = train['rating'].to_numpy() - 1\n\nX_test = test[scope].to_numpy()\ny_test = test['rating'].to_numpy() - 1\n\nparams = {\n    'eta': 0.1,\n    'max_depth': 8,\n    'alpha': 0.2,\n    'objective': 'multi:softmax',\n    'num_class': 5,\n    'eval_metric': 'mlogloss',\n    'n_estimators': 605,\n    'tree_method': 'gpu_hist',\n}\n\nvectorizer = TfidfVectorizer(min_df=200)\nX_train_vec = vectorizer.fit_transform(X_train)\nX_test_vec = vectorizer.transform(X_test)\n\nclf = xgb.XGBClassifier(**params)\nclf.fit(X_train_vec, y_train, verbose=False)\n\ny_pred = clf.predict(X_test_vec)\n\nprint(metrics.classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-02-17T13:07:46.586142Z","iopub.execute_input":"2023-02-17T13:07:46.586753Z","iopub.status.idle":"2023-02-17T13:09:19.409938Z","shell.execute_reply.started":"2023-02-17T13:07:46.586700Z","shell.execute_reply":"2023-02-17T13:09:19.407040Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.64      0.68      0.66      2500\n           1       0.42      0.40      0.41      2500\n           2       0.41      0.38      0.39      2500\n           3       0.53      0.52      0.52      2500\n           4       0.74      0.77      0.75      2500\n\n    accuracy                           0.55     12500\n   macro avg       0.55      0.55      0.55     12500\nweighted avg       0.55      0.55      0.55     12500\n\nCPU times: user 1min 35s, sys: 126 ms, total: 1min 35s\nWall time: 1min 32s\n","output_type":"stream"}]}]}