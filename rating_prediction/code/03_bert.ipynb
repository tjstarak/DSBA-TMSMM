{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T10:16:06.439872Z","iopub.status.busy":"2023-02-27T10:16:06.439066Z","iopub.status.idle":"2023-02-27T10:16:19.580524Z","shell.execute_reply":"2023-02-27T10:16:19.578824Z","shell.execute_reply.started":"2023-02-27T10:16:06.439815Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","import numpy as np\n","from transformers import BertTokenizer\n","from torch import nn\n","from transformers import BertModel\n","from sklearn import metrics\n","from torch.optim import Adam\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-02-27T10:16:19.586060Z","iopub.status.busy":"2023-02-27T10:16:19.584624Z","iopub.status.idle":"2023-02-27T10:16:21.674386Z","shell.execute_reply":"2023-02-27T10:16:21.673136Z","shell.execute_reply.started":"2023-02-27T10:16:19.586000Z"},"trusted":true},"outputs":[],"source":["reviews = pd.read_parquet('/kaggle/input/restaurant-reviews/reviews_sample_proc.parquet')\n","train = reviews.query('partition == \"train\"')\n","test = reviews.query('partition == \"test\"')\n","\n","translated_train = train[['translated', 'rating']].rename(columns={'translated': 'text'}).assign(**{'rating': lambda x: x['rating']-1})[:25000]\n","translated_test = test[['translated', 'rating']].rename(columns={'translated': 'text'}).assign(**{'rating': lambda x: x['rating']-1})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T10:16:21.676886Z","iopub.status.busy":"2023-02-27T10:16:21.676398Z","iopub.status.idle":"2023-02-27T10:16:31.044793Z","shell.execute_reply":"2023-02-27T10:16:31.043553Z","shell.execute_reply.started":"2023-02-27T10:16:21.676837Z"},"trusted":true},"outputs":[],"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        self.labels = df['rating'].to_list()\n","        self.texts = [\n","            tokenizer(text, padding='max_length', max_length = 512,\n","                truncation=True, return_tensors='pt') for text in df['text']\n","        ]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_batch_labels(self, idx):\n","        return np.array(self.labels[idx])\n","\n","    def get_batch_texts(self, idx):\n","        return self.texts[idx]\n","\n","    def __getitem__(self, idx):\n","\n","        batch_texts = self.get_batch_texts(idx)\n","        batch_y = self.get_batch_labels(idx)\n","\n","        return batch_texts, batch_y\n","    \n","class BertClassifier(nn.Module):\n","\n","    def __init__(self):\n","\n","        super(BertClassifier, self).__init__()\n","\n","        self.bert = BertModel.from_pretrained('bert-base-cased')\n","        self.linear = nn.Linear(768, 5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, input_id, mask):\n","\n","        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n","        linear_output = self.linear(pooled_output)\n","        final_layer = self.relu(linear_output)\n","\n","        return final_layer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-27T10:16:31.048538Z","iopub.status.busy":"2023-02-27T10:16:31.048023Z"},"trusted":true},"outputs":[],"source":["%%time\n","\n","torch.manual_seed(1234)\n","\n","def train(model, train_data, learning_rate, epochs):\n","\n","    train = Dataset(train_data)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr=learning_rate)\n","\n","    if use_cuda:\n","            model = model.cuda()\n","            criterion = criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","\n","        total_acc_train = 0\n","        total_loss_train = 0\n","\n","        for train_input, train_label in tqdm(train_dataloader):\n","\n","            train_label = train_label.to(device)\n","            mask = train_input['attention_mask'].to(device)\n","            input_id = train_input['input_ids'].squeeze(1).to(device)\n","\n","            output = model(input_id, mask)\n","\n","            batch_loss = criterion(output, train_label.long())\n","            total_loss_train += batch_loss.item()\n","\n","            acc = (output.argmax(dim=1) == train_label).sum().item()\n","            total_acc_train += acc\n","\n","            model.zero_grad()\n","            batch_loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","\n","        print(\n","            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n","            | Train Accuracy: {total_acc_train / len(train_data): .3f}'\n","        )\n","                  \n","EPOCHS = 4\n","model = BertClassifier()\n","\n","modules = [model.bert.embeddings, *model.bert.encoder.layer[:8]]\n","for module in modules:\n","    for param in module.parameters():\n","        param.requires_grad = False\n","        \n","LR = 5e-5\n","              \n","train(model, translated_train, LR, EPOCHS)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def evaluate(model, test_data):\n","\n","    test = Dataset(test_data)\n","\n","    test_dataloader = torch.utils.data.DataLoader(test, batch_size=64)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    if use_cuda:\n","        model = model.cuda()\n","\n","    y_pred = torch.empty(0) .to(device)\n","\n","    with torch.no_grad():\n","        for test_input, test_label in test_dataloader:\n","            \n","            test_label = test_label.to(device)\n","            mask = test_input['attention_mask'].to(device)\n","            input_id = test_input['input_ids'].squeeze(1).to(device)\n","\n","            output = model(input_id, mask)\n","\n","            y_pred = torch.cat([y_pred, output.argmax(dim=1)])\n","    \n","    return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["%%time\n","\n","results = evaluate(model, translated_test)\n","\n","print(metrics.classification_report(translated_test['rating'].to_numpy(), results.cpu().numpy()))"]}],"metadata":{"kernelspec":{"display_name":"tmsmm","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"056f66996a9c4d81c65e6002a1ca08da18a62e1c6e37a0ec081f5552e597d624"}}},"nbformat":4,"nbformat_minor":4}
