{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport numpy as np\nfrom transformers import HerbertTokenizer, RobertaModel\nfrom torch import nn\nfrom sklearn import metrics\nfrom torch.optim import Adam\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-02-27T15:09:48.960845Z","iopub.execute_input":"2023-02-27T15:09:48.961207Z","iopub.status.idle":"2023-02-27T15:09:48.967410Z","shell.execute_reply.started":"2023-02-27T15:09:48.961174Z","shell.execute_reply":"2023-02-27T15:09:48.966020Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"reviews = pd.read_parquet('/kaggle/input/restaurant-reviews/reviews_sample_proc.parquet')\ntrain = reviews.query('partition == \"train\"')\ntest = reviews.query('partition == \"test\"')\n\noriginal_train = train[['original', 'rating']].rename(columns={'original': 'text'}).assign(**{'rating': lambda x: x['rating']-1})[:25000]\noriginal_test = test[['original', 'rating']].rename(columns={'original': 'text'}).assign(**{'rating': lambda x: x['rating']-1})","metadata":{"execution":{"iopub.status.busy":"2023-02-27T15:09:58.914285Z","iopub.execute_input":"2023-02-27T15:09:58.914648Z","iopub.status.idle":"2023-02-27T15:09:59.961437Z","shell.execute_reply.started":"2023-02-27T15:09:58.914613Z","shell.execute_reply":"2023-02-27T15:09:59.960383Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = HerbertTokenizer.from_pretrained('allegro/herbert-klej-cased-tokenizer-v1')\n\nclass Dataset(torch.utils.data.Dataset):\n\n    def __init__(self, df):\n\n        self.labels = df['rating'].to_list()\n        self.texts = [\n            tokenizer(text, padding='max_length', max_length = 512,\n                truncation=True, return_tensors='pt') for text in df['text']\n        ]\n\n    def classes(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def get_batch_labels(self, idx):\n        return np.array(self.labels[idx])\n\n    def get_batch_texts(self, idx):\n        return self.texts[idx]\n\n    def __getitem__(self, idx):\n\n        batch_texts = self.get_batch_texts(idx)\n        batch_y = self.get_batch_labels(idx)\n\n        return batch_texts, batch_y\n    \nclass RobertaClassifier(nn.Module):\n\n    def __init__(self):\n\n        super().__init__()\n\n        self.bert = RobertaModel.from_pretrained('allegro/herbert-klej-cased-v1')\n        self.linear = nn.Linear(768, 5)\n        self.relu = nn.ReLU()\n\n    def forward(self, input_id, mask):\n\n        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n        linear_output = self.linear(pooled_output)\n        final_layer = self.relu(linear_output)\n\n        return final_layer","metadata":{"execution":{"iopub.status.busy":"2023-02-27T15:09:59.963122Z","iopub.execute_input":"2023-02-27T15:09:59.963520Z","iopub.status.idle":"2023-02-27T15:10:12.864784Z","shell.execute_reply.started":"2023-02-27T15:09:59.963481Z","shell.execute_reply":"2023-02-27T15:10:12.863723Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f12270f1a554d28baeec35ddf8ee280"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/591k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2710b61ca904bc79c89cd715ce8b3f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/300 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bba9cade07ca4cd7affb9ddc4489f924"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/341 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8da482191e4a4cb4b86e2ec1917f97f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10e57a6ea7d34d8686bf561426b2efe7"}},"metadata":{}},{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'XLMTokenizer'. \nThe class this function is called from is 'HerbertTokenizer'.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\ntorch.manual_seed(12345)\n\ndef train(model, train_data, learning_rate, epochs):\n\n    train = Dataset(train_data)\n\n    train_dataloader = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = Adam(model.parameters(), lr=learning_rate)\n\n    if use_cuda:\n            model = model.cuda()\n            criterion = criterion.cuda()\n\n    for epoch_num in range(epochs):\n\n        total_acc_train = 0\n        total_loss_train = 0\n\n        for train_input, train_label in tqdm(train_dataloader):\n\n            train_label = train_label.to(device)\n            mask = train_input['attention_mask'].to(device)\n            input_id = train_input['input_ids'].squeeze(1).to(device)\n\n            output = model(input_id, mask)\n\n            batch_loss = criterion(output, train_label.long())\n            total_loss_train += batch_loss.item()\n\n            acc = (output.argmax(dim=1) == train_label).sum().item()\n            total_acc_train += acc\n\n            model.zero_grad()\n            batch_loss.backward()\n            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n\n        print(\n            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n            | Train Accuracy: {total_acc_train / len(train_data): .3f}'\n        )\n                  \nEPOCHS = 4\nmodel = RobertaClassifier()\n\nmodules = [model.bert.embeddings, *model.bert.encoder.layer[:8]]\nfor module in modules:\n    for param in module.parameters():\n        param.requires_grad = False\n        \nLR = 1e-5\n              \ntrain(model, original_train, LR, EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:02:08.811203Z","iopub.execute_input":"2023-02-27T16:02:08.811904Z","iopub.status.idle":"2023-02-27T16:48:26.286173Z","shell.execute_reply.started":"2023-02-27T16:02:08.811867Z","shell.execute_reply":"2023-02-27T16:48:26.285077Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"100%|██████████| 1563/1563 [11:22<00:00,  2.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 1 | Train Loss:  0.088             | Train Accuracy:  0.314\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [11:22<00:00,  2.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 2 | Train Loss:  0.053             | Train Accuracy:  0.645\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [11:23<00:00,  2.29it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epochs: 3 | Train Loss:  0.044             | Train Accuracy:  0.707\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1563/1563 [11:23<00:00,  2.29it/s]","output_type":"stream"},{"name":"stdout","text":"Epochs: 4 | Train Loss:  0.037             | Train Accuracy:  0.758\nCPU times: user 46min 4s, sys: 4.54 s, total: 46min 9s\nWall time: 46min 17s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n\ndef evaluate(model, test_data):\n\n    test = Dataset(test_data)\n\n    test_dataloader = torch.utils.data.DataLoader(test, batch_size=64)\n\n    use_cuda = torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n\n    if use_cuda:\n        model = model.cuda()\n\n    y_pred = torch.empty(0).to(device)\n\n    with torch.no_grad():\n        for test_input, test_label in tqdm(test_dataloader):\n            \n            test_label = test_label.to(device)\n            mask = test_input['attention_mask'].to(device)\n            input_id = test_input['input_ids'].squeeze(1).to(device)\n\n            output = model(input_id, mask)\n\n            y_pred = torch.cat([y_pred, output.argmax(dim=1)])\n    \n    return y_pred\n\nmodel.eval()\nresults = evaluate(model, original_test)\n\nprint(metrics.classification_report(original_test['rating'].to_numpy(), results.cpu().numpy()))","metadata":{"execution":{"iopub.status.busy":"2023-02-27T16:52:07.826844Z","iopub.execute_input":"2023-02-27T16:52:07.827791Z","iopub.status.idle":"2023-02-27T16:55:46.779423Z","shell.execute_reply.started":"2023-02-27T16:52:07.827741Z","shell.execute_reply":"2023-02-27T16:55:46.778069Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 196/196 [03:16<00:00,  1.00s/it]\n","output_type":"stream"},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.75      0.74      0.74      2500\n           1       0.54      0.60      0.57      2500\n           2       0.55      0.60      0.57      2500\n           3       0.73      0.56      0.63      2500\n           4       0.81      0.87      0.84      2500\n\n    accuracy                           0.67     12500\n   macro avg       0.68      0.67      0.67     12500\nweighted avg       0.68      0.67      0.67     12500\n\nCPU times: user 3min 38s, sys: 305 ms, total: 3min 38s\nWall time: 3min 38s\n","output_type":"stream"}]}]}